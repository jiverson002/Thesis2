Similarity Analyser 2.4.0 - http://www.harukizaemon.com/simian
Copyright (c) 2003-2015 Simon Harris.  All rights reserved.
Simian is not free unless used solely for non-commercial or evaluation purposes.
{failOnDuplication=true, ignoreCharacterCase=true, ignoreCurlyBraces=true, ignoreIdentifierCase=true, ignoreModifiers=true, ignoreStringCase=true, reportDuplicateText=true, threshold=6}
Found 6 duplicate lines in the following files:
 Between lines 115 and 121 in /home/ooee/Thesis2/studentFiles/F16/aadrianc/original/cclient.c
 Between lines 103 and 109 in /home/ooee/Thesis2/studentFiles/F16/aadrianc/original/cclient.c
    packet = makePacketMssg(CLIENT_MESSAGE, destLen, dest,    							 srcLen, myHandle, toSend);
    if(sendPacket(packet, socket) < 0) {
      perror("Packet Message");
      exit(1);
    }
    free(packet);
=====================================================================
Found 6 duplicate lines in the following files:
 Between lines 107 and 114 in /home/ooee/Thesis2/studentFiles/F16/aadrianc/original/cclient.c
 Between lines 67 and 74 in /home/ooee/Thesis2/studentFiles/F16/aadrianc/original/cclient.c
      exit(1);    }
    free(packet);
    mssgNum--;
  }
  free(toSend);
  toSend = malloc(theRest);
  memcpy(toSend, mssg + consumed, theRest);
=====================================================================
Found 8 duplicate lines in the following files:
 Between lines 92 and 102 in /home/ooee/Thesis2/studentFiles/F16/aadrianc/original/cclient.c
 Between lines 53 and 63 in /home/ooee/Thesis2/studentFiles/F16/aadrianc/original/cclient.c
  int mssgNum = (strlen(mssg) + 1) / maxMssgLen;  int consumed = 0;
  /* add mssgNum because that's how many nulls we'll end up with
     which we need to account for in the packet*/
  int theRest = ((strlen(mssg) + 1) % maxMssgLen) + mssgNum;

  toSend = malloc(maxMssgLen);
  while(mssgNum > 0) {
    memcpy(toSend, mssg + consumed, maxMssgLen - 1);
    toSend[maxMssgLen - 1] = 0;
    consumed += maxMssgLen - 1;
=====================================================================
Found 40 duplicate lines in 6 blocks in 1 files
Processed a total of 543 significant (926 raw) lines in 5 files
Processing time: 0.036sec
